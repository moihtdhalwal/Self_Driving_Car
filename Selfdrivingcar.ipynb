{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of selfdrivingcar2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YROe8OE6z3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/driving_dataset.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/data\")\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WQR92qF6-vh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import image\n",
        "import keras\n",
        "\n",
        "data = pandas.read_csv('/content/drive/My Drive/data.txt',header = None,sep=' ' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ8OWKxy6dbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEyJJEt27rgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d3b63da-6ff1-4c50-dd1c-ddea7677dbb3"
      },
      "source": [
        "x_data = data[:,0]\n",
        "y_data = np.array([float(i) for i in data[:,-1]])\n",
        "print(x_data.shape,y_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(45406,) (45406,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJppL6je8AoO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8db4ec47-e75b-4394-fecb-601149c8e43f"
      },
      "source": [
        "l = (int)(x_data.shape[0]*0.8)\n",
        "xtrain = x_data[:l]\n",
        "ytrain = y_data[:l]\n",
        "xtest = x_data[l:]\n",
        "ytest = y_data[l:]\n",
        "print(xtrain.shape,xtest.shape,ytrain.shape,ytest.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(36324,) (9082,) (36324,) (9082,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjRmJwXz8HtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import random\n",
        "c = list(zip(xtrain,ytrain))\n",
        "random.shuffle(c)\n",
        "xtrain,ytrain = zip(*c)\n",
        "\n",
        "\n",
        "c = list(zip(xtest,ytest))\n",
        "random.shuffle(c)\n",
        "xtest,ytest = zip(*c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpiWBseE8Rnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "def LoadBatch(batch_size,i,xdata,ydata):\n",
        "  xd = []\n",
        "  yd = []\n",
        "  Pointer = 0;\n",
        "  if i==len(xdata)//batch_size - 1:\n",
        "      batch_size = len(xdata)%batch_size\n",
        "  while Pointer<batch_size:\n",
        "    img = image.load_img(\"/content/data/driving_dataset/\"+xdata[(Pointer+i*batch_size)%l],color_mode='rgb',target_size=[200,200])\n",
        "    img = image.img_to_array(img)/255.0\n",
        "    xd.append(img)\n",
        "    yd.append(ydata[(Pointer+i*batch_size)%l]*np.pi/180)\n",
        "    Pointer = Pointer+1\n",
        "  return np.array(xd),np.array(yd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_ifoO7o9M7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Conv2D,Flatten, Dense, Dropout, BatchNormalization, LeakyReLU, MaxPool2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras import regularizers\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# from keras.adv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaiVk3zdhynF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "outputId": "d2e3cb5b-1637-4f72-92c4-04c9a4ff360a"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(24,(5,5),activation='relu',input_shape=(200,200,3),kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(36,(5,5),activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(48,(3,3),activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64,(3,3),activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128,(3,3),activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128,activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64,activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(1,activation='tanh',kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_17 (Conv2D)           (None, 196, 196, 24)      1824      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 98, 98, 24)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 98, 98, 24)        96        \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 94, 94, 36)        21636     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 47, 47, 36)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 47, 47, 36)        144       \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 45, 45, 48)        15600     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 22, 22, 48)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 22, 22, 48)        192       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 20, 20, 64)        27712     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 10, 10, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 412,421\n",
            "Trainable params: 411,821\n",
            "Non-trainable params: 600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2lCQTSdT0Tp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = Adam(0.0001),loss = 'mse',metrics=['mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_rc_LW5T57u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f4fd7cc-8a3e-4520-aa91-29ca3fc4f282"
      },
      "source": [
        "epochs = 5\n",
        "batch_size = 128\n",
        "num = len(xtrain)\n",
        "\n",
        "c=0\n",
        "l = len(xtest)\n",
        "\n",
        "# train over the dataset about 30 times\n",
        "for epoch in range(epochs):\n",
        "    for i in range(int(num//batch_size)):\n",
        "        xs, ys = LoadBatch(batch_size,i,xtest,ytest)\n",
        "        ys.reshape(-1,1)\n",
        "\n",
        "        model.fit(xs,ys,verbose=0)\n",
        "\n",
        "        if i%10 == 0:\n",
        "            score_train = model.evaluate(xs,ys,verbose=0)\n",
        "            xs1, ys1 = LoadBatch(batch_size,c,xtrain,ytrain)\n",
        "            c+=1\n",
        "            ys1.reshape(-1,1)\n",
        "            score_test = model.evaluate(xs1,ys1,verbose=0)\n",
        "            print(\"Epoch:%d Step:%d Train loss:%f Train mae:%f Test loss:%f Test mae:%f\\n\"%(epoch+1,i,score_train[0],score_train[1],score_test[0],score_test[1]))\n",
        "\n",
        "        if i%100 == 0:\n",
        "            model.save_weights(\"/content/drive/My Drive/gkl7.h5\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1 Step:0 Train loss:5.731159 Train mae:0.293378 Test loss:6.185930 Test mae:0.328742\n",
            "\n",
            "Epoch:1 Step:10 Train loss:5.642132 Train mae:0.265078 Test loss:5.806211 Test mae:0.351447\n",
            "\n",
            "Epoch:1 Step:20 Train loss:5.648902 Train mae:0.295390 Test loss:6.124649 Test mae:0.416094\n",
            "\n",
            "Epoch:1 Step:30 Train loss:5.493180 Train mae:0.260992 Test loss:5.375972 Test mae:0.263368\n",
            "\n",
            "Epoch:1 Step:40 Train loss:5.242342 Train mae:0.168602 Test loss:5.491564 Test mae:0.336270\n",
            "\n",
            "Epoch:1 Step:50 Train loss:5.193392 Train mae:0.267289 Test loss:5.228124 Test mae:0.267044\n",
            "\n",
            "Epoch:1 Step:60 Train loss:5.240770 Train mae:0.292058 Test loss:5.317111 Test mae:0.342019\n",
            "\n",
            "Epoch:1 Step:70 Train loss:5.137605 Train mae:0.424827 Test loss:5.214151 Test mae:0.449278\n",
            "\n",
            "Epoch:1 Step:80 Train loss:4.981936 Train mae:0.354875 Test loss:5.101775 Test mae:0.402843\n",
            "\n",
            "Epoch:1 Step:90 Train loss:5.008132 Train mae:0.453213 Test loss:5.258098 Test mae:0.509665\n",
            "\n",
            "Epoch:1 Step:100 Train loss:4.819540 Train mae:0.354652 Test loss:5.063966 Test mae:0.486553\n",
            "\n",
            "Epoch:1 Step:110 Train loss:4.653492 Train mae:0.280263 Test loss:4.894746 Test mae:0.445451\n",
            "\n",
            "Epoch:1 Step:120 Train loss:4.630952 Train mae:0.260345 Test loss:4.731230 Test mae:0.412905\n",
            "\n",
            "Epoch:1 Step:130 Train loss:4.405237 Train mae:0.154836 Test loss:4.726320 Test mae:0.379380\n",
            "\n",
            "Epoch:1 Step:140 Train loss:4.250316 Train mae:0.136931 Test loss:4.415423 Test mae:0.337443\n",
            "\n",
            "Epoch:1 Step:150 Train loss:4.160696 Train mae:0.122080 Test loss:4.723028 Test mae:0.465721\n",
            "\n",
            "Epoch:1 Step:160 Train loss:4.106336 Train mae:0.131720 Test loss:4.335844 Test mae:0.360219\n",
            "\n",
            "Epoch:1 Step:170 Train loss:3.949543 Train mae:0.097746 Test loss:4.394908 Test mae:0.382994\n",
            "\n",
            "Epoch:1 Step:180 Train loss:3.842399 Train mae:0.096875 Test loss:4.010320 Test mae:0.342029\n",
            "\n",
            "Epoch:1 Step:190 Train loss:3.783804 Train mae:0.113310 Test loss:3.970377 Test mae:0.313600\n",
            "\n",
            "Epoch:1 Step:200 Train loss:3.711829 Train mae:0.145975 Test loss:3.897499 Test mae:0.356210\n",
            "\n",
            "Epoch:1 Step:210 Train loss:3.539098 Train mae:0.082727 Test loss:3.919495 Test mae:0.367559\n",
            "\n",
            "Epoch:1 Step:220 Train loss:3.450783 Train mae:0.084021 Test loss:3.978392 Test mae:0.396388\n",
            "\n",
            "Epoch:1 Step:230 Train loss:3.353276 Train mae:0.087681 Test loss:3.777998 Test mae:0.451321\n",
            "\n",
            "Epoch:1 Step:240 Train loss:3.293645 Train mae:0.103281 Test loss:3.552738 Test mae:0.362919\n",
            "\n",
            "Epoch:1 Step:250 Train loss:3.172529 Train mae:0.085821 Test loss:3.439294 Test mae:0.362837\n",
            "\n",
            "Epoch:1 Step:260 Train loss:3.124246 Train mae:0.113121 Test loss:3.298755 Test mae:0.352427\n",
            "\n",
            "Epoch:1 Step:270 Train loss:3.038575 Train mae:0.106354 Test loss:3.254588 Test mae:0.383559\n",
            "\n",
            "Epoch:1 Step:280 Train loss:2.918868 Train mae:0.092082 Test loss:3.193824 Test mae:0.366025\n",
            "\n",
            "Epoch:2 Step:0 Train loss:2.898026 Train mae:0.105226 Test loss:3.140887 Test mae:0.363799\n",
            "\n",
            "Epoch:2 Step:10 Train loss:2.812566 Train mae:0.104534 Test loss:3.049850 Test mae:0.358395\n",
            "\n",
            "Epoch:2 Step:20 Train loss:2.747720 Train mae:0.111349 Test loss:2.890721 Test mae:0.325915\n",
            "\n",
            "Epoch:2 Step:30 Train loss:2.645159 Train mae:0.098830 Test loss:3.083569 Test mae:0.437730\n",
            "\n",
            "Epoch:2 Step:40 Train loss:2.515312 Train mae:0.061349 Test loss:2.850397 Test mae:0.390348\n",
            "\n",
            "Epoch:2 Step:50 Train loss:2.438531 Train mae:0.067814 Test loss:2.588495 Test mae:0.290358\n",
            "\n",
            "Epoch:2 Step:60 Train loss:2.440648 Train mae:0.113246 Test loss:2.562974 Test mae:0.280086\n",
            "\n",
            "Epoch:2 Step:80 Train loss:2.198450 Train mae:0.059894 Test loss:2.326591 Test mae:0.281071\n",
            "\n",
            "Epoch:2 Step:90 Train loss:2.202185 Train mae:0.115014 Test loss:2.552078 Test mae:0.373697\n",
            "\n",
            "Epoch:2 Step:100 Train loss:2.109035 Train mae:0.087635 Test loss:2.391185 Test mae:0.318347\n",
            "\n",
            "Epoch:2 Step:110 Train loss:2.027931 Train mae:0.089734 Test loss:2.246319 Test mae:0.329642\n",
            "\n",
            "Epoch:2 Step:120 Train loss:2.055605 Train mae:0.142735 Test loss:2.107558 Test mae:0.318104\n",
            "\n",
            "Epoch:2 Step:130 Train loss:1.905224 Train mae:0.088591 Test loss:2.107173 Test mae:0.318191\n",
            "\n",
            "Epoch:2 Step:140 Train loss:1.794050 Train mae:0.066233 Test loss:2.084728 Test mae:0.353760\n",
            "\n",
            "Epoch:2 Step:150 Train loss:1.751011 Train mae:0.075936 Test loss:2.452873 Test mae:0.371705\n",
            "\n",
            "Epoch:2 Step:160 Train loss:1.738244 Train mae:0.092329 Test loss:1.906621 Test mae:0.317096\n",
            "\n",
            "Epoch:2 Step:170 Train loss:1.630726 Train mae:0.064844 Test loss:2.025087 Test mae:0.393015\n",
            "\n",
            "Epoch:2 Step:180 Train loss:1.571573 Train mae:0.070525 Test loss:2.091181 Test mae:0.412833\n",
            "\n",
            "Epoch:2 Step:190 Train loss:1.557090 Train mae:0.089432 Test loss:1.914041 Test mae:0.406974\n",
            "\n",
            "Epoch:2 Step:200 Train loss:1.525721 Train mae:0.112385 Test loss:1.962540 Test mae:0.390208\n",
            "\n",
            "Epoch:2 Step:210 Train loss:1.407430 Train mae:0.070514 Test loss:1.714705 Test mae:0.370050\n",
            "\n",
            "Epoch:2 Step:220 Train loss:1.360915 Train mae:0.066857 Test loss:1.653258 Test mae:0.350635\n",
            "\n",
            "Epoch:2 Step:230 Train loss:1.314425 Train mae:0.073326 Test loss:1.490355 Test mae:0.309179\n",
            "\n",
            "Epoch:2 Step:240 Train loss:1.303288 Train mae:0.083399 Test loss:1.799960 Test mae:0.451291\n",
            "\n",
            "Epoch:2 Step:250 Train loss:1.231265 Train mae:0.072578 Test loss:1.363092 Test mae:0.312478\n",
            "\n",
            "Epoch:2 Step:260 Train loss:1.230118 Train mae:0.103857 Test loss:1.658573 Test mae:0.372837\n",
            "\n",
            "Epoch:2 Step:270 Train loss:1.194246 Train mae:0.094029 Test loss:1.420657 Test mae:0.371086\n",
            "\n",
            "Epoch:2 Step:280 Train loss:1.120936 Train mae:0.075778 Test loss:1.362656 Test mae:0.304663\n",
            "\n",
            "Epoch:3 Step:0 Train loss:1.113775 Train mae:0.084418 Test loss:1.297820 Test mae:0.332941\n",
            "\n",
            "Epoch:3 Step:10 Train loss:1.077758 Train mae:0.097008 Test loss:1.213849 Test mae:0.286795\n",
            "\n",
            "Epoch:3 Step:20 Train loss:1.060422 Train mae:0.103145 Test loss:1.353933 Test mae:0.360444\n",
            "\n",
            "Epoch:3 Step:30 Train loss:1.003081 Train mae:0.091705 Test loss:1.165912 Test mae:0.295298\n",
            "\n",
            "Epoch:3 Step:40 Train loss:0.921338 Train mae:0.061520 Test loss:1.247432 Test mae:0.331627\n",
            "\n",
            "Epoch:3 Step:50 Train loss:0.887172 Train mae:0.057491 Test loss:1.113991 Test mae:0.285037\n",
            "\n",
            "Epoch:3 Step:60 Train loss:0.934002 Train mae:0.102434 Test loss:1.203018 Test mae:0.368770\n",
            "\n",
            "Epoch:3 Step:70 Train loss:0.831882 Train mae:0.071831 Test loss:1.151581 Test mae:0.346142\n",
            "\n",
            "Epoch:3 Step:80 Train loss:0.779235 Train mae:0.047506 Test loss:1.062442 Test mae:0.330390\n",
            "\n",
            "Epoch:3 Step:90 Train loss:0.826978 Train mae:0.108592 Test loss:1.119886 Test mae:0.383434\n",
            "\n",
            "Epoch:3 Step:100 Train loss:0.775058 Train mae:0.079257 Test loss:0.982915 Test mae:0.310751\n",
            "\n",
            "Epoch:3 Step:110 Train loss:0.736883 Train mae:0.085185 Test loss:1.038154 Test mae:0.365981\n",
            "\n",
            "Epoch:3 Step:120 Train loss:0.802390 Train mae:0.127024 Test loss:0.932810 Test mae:0.305692\n",
            "\n",
            "Epoch:3 Step:130 Train loss:0.692365 Train mae:0.082775 Test loss:1.380776 Test mae:0.392629\n",
            "\n",
            "Epoch:3 Step:140 Train loss:0.619876 Train mae:0.057709 Test loss:1.012106 Test mae:0.295175\n",
            "\n",
            "Epoch:3 Step:150 Train loss:0.615806 Train mae:0.073714 Test loss:1.406652 Test mae:0.376469\n",
            "\n",
            "Epoch:3 Step:160 Train loss:0.639385 Train mae:0.093551 Test loss:0.702255 Test mae:0.260872\n",
            "\n",
            "Epoch:3 Step:170 Train loss:0.567627 Train mae:0.064062 Test loss:0.898479 Test mae:0.342194\n",
            "\n",
            "Epoch:3 Step:180 Train loss:0.544516 Train mae:0.069245 Test loss:0.666446 Test mae:0.260275\n",
            "\n",
            "Epoch:3 Step:190 Train loss:0.565231 Train mae:0.098727 Test loss:0.795192 Test mae:0.326844\n",
            "\n",
            "Epoch:3 Step:200 Train loss:0.565488 Train mae:0.113391 Test loss:0.635591 Test mae:0.264227\n",
            "\n",
            "Epoch:3 Step:210 Train loss:0.478932 Train mae:0.063588 Test loss:0.833400 Test mae:0.383533\n",
            "\n",
            "Epoch:3 Step:220 Train loss:0.462877 Train mae:0.061455 Test loss:0.684956 Test mae:0.290938\n",
            "\n",
            "Epoch:3 Step:230 Train loss:0.449277 Train mae:0.072224 Test loss:0.727520 Test mae:0.357104\n",
            "\n",
            "Epoch:3 Step:240 Train loss:0.469208 Train mae:0.090497 Test loss:0.691634 Test mae:0.327045\n",
            "\n",
            "Epoch:3 Step:250 Train loss:0.426197 Train mae:0.077797 Test loss:0.603391 Test mae:0.293890\n",
            "\n",
            "Epoch:3 Step:260 Train loss:0.451331 Train mae:0.097102 Test loss:0.710345 Test mae:0.290139\n",
            "\n",
            "Epoch:3 Step:270 Train loss:0.443344 Train mae:0.093753 Test loss:0.457297 Test mae:0.203782\n",
            "\n",
            "Epoch:3 Step:280 Train loss:0.395154 Train mae:0.072003 Test loss:0.878635 Test mae:0.393151\n",
            "\n",
            "Epoch:4 Step:0 Train loss:0.399002 Train mae:0.090629 Test loss:0.626951 Test mae:0.325987\n",
            "\n",
            "Epoch:4 Step:10 Train loss:0.384174 Train mae:0.084304 Test loss:0.752272 Test mae:0.332825\n",
            "\n",
            "Epoch:4 Step:20 Train loss:0.394293 Train mae:0.104310 Test loss:0.492969 Test mae:0.303531\n",
            "\n",
            "Epoch:4 Step:30 Train loss:0.361562 Train mae:0.092897 Test loss:0.501112 Test mae:0.225966\n",
            "\n",
            "Epoch:4 Step:40 Train loss:0.302440 Train mae:0.057310 Test loss:0.568286 Test mae:0.308215\n",
            "\n",
            "Epoch:4 Step:50 Train loss:0.291779 Train mae:0.060253 Test loss:0.633161 Test mae:0.298372\n",
            "\n",
            "Epoch:4 Step:60 Train loss:0.363712 Train mae:0.109793 Test loss:0.752495 Test mae:0.322258\n",
            "\n",
            "Epoch:4 Step:70 Train loss:0.278788 Train mae:0.074281 Test loss:0.611692 Test mae:0.344139\n",
            "\n",
            "Epoch:4 Step:80 Train loss:0.250206 Train mae:0.058938 Test loss:0.487359 Test mae:0.281965\n",
            "\n",
            "Epoch:4 Step:90 Train loss:0.316622 Train mae:0.106784 Test loss:0.479101 Test mae:0.309654\n",
            "\n",
            "Epoch:4 Step:100 Train loss:0.284419 Train mae:0.089565 Test loss:0.426443 Test mae:0.279046\n",
            "\n",
            "Epoch:4 Step:110 Train loss:0.259186 Train mae:0.081089 Test loss:0.488846 Test mae:0.326849\n",
            "\n",
            "Epoch:4 Step:120 Train loss:0.348845 Train mae:0.124441 Test loss:0.406585 Test mae:0.249568\n",
            "\n",
            "Epoch:4 Step:130 Train loss:0.257281 Train mae:0.083343 Test loss:0.467593 Test mae:0.324330\n",
            "\n",
            "Epoch:4 Step:140 Train loss:0.201841 Train mae:0.060699 Test loss:0.423551 Test mae:0.278268\n",
            "\n",
            "Epoch:4 Step:150 Train loss:0.212491 Train mae:0.066252 Test loss:0.325800 Test mae:0.208682\n",
            "\n",
            "Epoch:4 Step:160 Train loss:0.254582 Train mae:0.093904 Test loss:0.501318 Test mae:0.272052\n",
            "\n",
            "Epoch:4 Step:170 Train loss:0.197404 Train mae:0.068142 Test loss:0.454599 Test mae:0.318610\n",
            "\n",
            "Epoch:4 Step:180 Train loss:0.188056 Train mae:0.066171 Test loss:0.310545 Test mae:0.252155\n",
            "\n",
            "Epoch:4 Step:190 Train loss:0.224845 Train mae:0.096189 Test loss:0.314635 Test mae:0.203396\n",
            "\n",
            "Epoch:4 Step:200 Train loss:0.239316 Train mae:0.115371 Test loss:0.721778 Test mae:0.364798\n",
            "\n",
            "Epoch:4 Step:210 Train loss:0.164155 Train mae:0.059278 Test loss:0.224715 Test mae:0.197041\n",
            "\n",
            "Epoch:4 Step:220 Train loss:0.162116 Train mae:0.063862 Test loss:0.497831 Test mae:0.306201\n",
            "\n",
            "Epoch:4 Step:230 Train loss:0.161895 Train mae:0.071454 Test loss:0.401014 Test mae:0.243381\n",
            "\n",
            "Epoch:4 Step:240 Train loss:0.191284 Train mae:0.085914 Test loss:0.382084 Test mae:0.309184\n",
            "\n",
            "Epoch:4 Step:250 Train loss:0.160236 Train mae:0.071142 Test loss:0.228815 Test mae:0.221761\n",
            "\n",
            "Epoch:4 Step:260 Train loss:0.198232 Train mae:0.102198 Test loss:0.339166 Test mae:0.247986\n",
            "\n",
            "Epoch:4 Step:270 Train loss:0.199510 Train mae:0.088424 Test loss:0.331007 Test mae:0.266363\n",
            "\n",
            "Epoch:4 Step:280 Train loss:0.162645 Train mae:0.073849 Test loss:0.820256 Test mae:0.290938\n",
            "\n",
            "Epoch:5 Step:0 Train loss:0.169594 Train mae:0.099211 Test loss:0.296920 Test mae:0.252596\n",
            "\n",
            "Epoch:5 Step:10 Train loss:0.165694 Train mae:0.086629 Test loss:0.488034 Test mae:0.322265\n",
            "\n",
            "Epoch:5 Step:20 Train loss:0.182469 Train mae:0.099799 Test loss:0.579453 Test mae:0.347194\n",
            "\n",
            "Epoch:5 Step:30 Train loss:0.157453 Train mae:0.073717 Test loss:0.476275 Test mae:0.348704\n",
            "\n",
            "Epoch:5 Step:40 Train loss:0.109555 Train mae:0.059711 Test loss:0.626766 Test mae:0.357975\n",
            "\n",
            "Epoch:5 Step:50 Train loss:0.106734 Train mae:0.053248 Test loss:0.361907 Test mae:0.277420\n",
            "\n",
            "Epoch:5 Step:60 Train loss:0.184219 Train mae:0.097706 Test loss:0.326463 Test mae:0.261123\n",
            "\n",
            "Epoch:5 Step:70 Train loss:0.111389 Train mae:0.070418 Test loss:0.238795 Test mae:0.224156\n",
            "\n",
            "Epoch:5 Step:80 Train loss:0.087444 Train mae:0.049825 Test loss:0.629162 Test mae:0.372450\n",
            "\n",
            "Epoch:5 Step:90 Train loss:0.160847 Train mae:0.100142 Test loss:0.206029 Test mae:0.234912\n",
            "\n",
            "Epoch:5 Step:100 Train loss:0.135790 Train mae:0.072625 Test loss:0.442892 Test mae:0.248548\n",
            "\n",
            "Epoch:5 Step:110 Train loss:0.118272 Train mae:0.083413 Test loss:0.330152 Test mae:0.266275\n",
            "\n",
            "Epoch:5 Step:120 Train loss:0.212701 Train mae:0.126280 Test loss:0.286224 Test mae:0.228756\n",
            "\n",
            "Epoch:5 Step:130 Train loss:0.126619 Train mae:0.082787 Test loss:0.250114 Test mae:0.254272\n",
            "\n",
            "Epoch:5 Step:140 Train loss:0.076330 Train mae:0.061336 Test loss:0.246712 Test mae:0.254665\n",
            "\n",
            "Epoch:5 Step:150 Train loss:0.095180 Train mae:0.072282 Test loss:0.381867 Test mae:0.307375\n",
            "\n",
            "Epoch:5 Step:160 Train loss:0.139619 Train mae:0.087498 Test loss:0.230190 Test mae:0.214386\n",
            "\n",
            "Epoch:5 Step:170 Train loss:0.087539 Train mae:0.061127 Test loss:0.325774 Test mae:0.257396\n",
            "\n",
            "Epoch:5 Step:180 Train loss:0.083785 Train mae:0.059019 Test loss:0.254991 Test mae:0.223087\n",
            "\n",
            "Epoch:5 Step:190 Train loss:0.126422 Train mae:0.097066 Test loss:0.414928 Test mae:0.307432\n",
            "\n",
            "Epoch:5 Step:200 Train loss:0.143945 Train mae:0.110430 Test loss:0.317728 Test mae:0.283501\n",
            "\n",
            "Epoch:5 Step:210 Train loss:0.073509 Train mae:0.048133 Test loss:0.264656 Test mae:0.250863\n",
            "\n",
            "Epoch:5 Step:220 Train loss:0.074925 Train mae:0.052709 Test loss:0.301933 Test mae:0.238301\n",
            "\n",
            "Epoch:5 Step:230 Train loss:0.078092 Train mae:0.069304 Test loss:0.229010 Test mae:0.225779\n",
            "\n",
            "Epoch:5 Step:240 Train loss:0.113410 Train mae:0.084646 Test loss:0.478894 Test mae:0.337377\n",
            "\n",
            "Epoch:5 Step:250 Train loss:0.084924 Train mae:0.067595 Test loss:0.159999 Test mae:0.235173\n",
            "\n",
            "Epoch:5 Step:260 Train loss:0.125234 Train mae:0.091121 Test loss:0.786998 Test mae:0.340309\n",
            "\n",
            "Epoch:5 Step:270 Train loss:0.130757 Train mae:0.090001 Test loss:0.596901 Test mae:0.251547\n",
            "\n",
            "Epoch:5 Step:280 Train loss:0.097696 Train mae:0.070536 Test loss:0.694888 Test mae:0.291370\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}